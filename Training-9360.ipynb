{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocessing\n",
    "import tools.image as T\n",
    "\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "#from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "#from inception_v4 import InceptionV4, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from types import SimpleNamespace\n",
    "\n",
    "IM_WIDTH, IM_HEIGHT = 299, 299 # fixed size for InceptionV3, Inception ResNet V2 and Inception V4\n",
    "EPOCHS = 100\n",
    "BAT_SIZE = 16\n",
    "FC_SIZE = 1024\n",
    "NB_LAYERS_TO_FREEZE = 172 # 165 ou ou 197\n",
    "\n",
    "#NB_LAYERS_TO_FREEZE = 249 # Inception V3\n",
    "#NB_LAYERS_TO_FREEZE = 618 # Inception ResNet V2\n",
    "#NB_LAYERS_TO_FREEZE = 369 # Inception V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(weights_path='weights_checkpoint.h5', patience=30, monitor='val_loss'):\n",
    "    early_stopping = EarlyStopping(verbose=1, patience=patience, monitor=monitor, min_delta=0.01)\n",
    "    model_checkpoint = ModelCheckpoint(weights_path,\n",
    "                                       save_best_only=True,\n",
    "                                       save_weights_only=True,\n",
    "                                       monitor=monitor)\n",
    "    return [early_stopping, model_checkpoint]\n",
    "\n",
    "def get_nb_files(directory):\n",
    "    \"\"\"Get number of files by searching directory recursively\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for r, dirs, files in os.walk(directory):\n",
    "        for dr in dirs:\n",
    "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "\n",
    "    Args:\n",
    "        base_model: keras model excluding top\n",
    "        nb_classes: # of classes\n",
    "\n",
    "    Returns:\n",
    "        new keras model with last layer\n",
    "    \"\"\"\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(FC_SIZE, activation = 'relu')(x) # new FC layer, random init\n",
    "    predictions = Dense(nb_classes, activation = 'softmax')(x) # new softmax layer\n",
    "    model = Model(inputs = base_model.input, outputs = predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_to_finetune(model):\n",
    "    \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top layers.\n",
    "\n",
    "    note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
    "\n",
    "    Args:\n",
    "        model: keras model\n",
    "    \"\"\"\n",
    "    for layer in model.layers[:NB_LAYERS_TO_FREEZE]:\n",
    "         layer.trainable = False\n",
    "    for layer in model.layers[NB_LAYERS_TO_FREEZE:]:\n",
    "         layer.trainable = True\n",
    "    model.compile(optimizer = SGD(lr = 0.0001, momentum = 0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"\n",
    "    nb_train_samples = get_nb_files(args.train_dir)\n",
    "    nb_classes = len(glob.glob(args.train_dir + \"/*\"))\n",
    "    nb_val_samples = get_nb_files(args.val_dir)\n",
    "    epochs = int(args.epochs)\n",
    "    batch_size = int(args.batch_size)\n",
    "    \n",
    "    '''try:\n",
    "        pool.terminate()\n",
    "    except:\n",
    "        pass\n",
    "    n_process = 7\n",
    "    pool = multiprocessing.Pool(processes = n_process)'''\n",
    "\n",
    "    # data prep\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input,\n",
    "        rotation_range = 45,\n",
    "        width_shift_range = 0.2,\n",
    "        height_shift_range = 0.2,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        #pool = pool\n",
    "    )\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input,\n",
    "        rotation_range = 45,\n",
    "        width_shift_range = 0.2,\n",
    "        height_shift_range = 0.2,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        #pool = pool\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        args.train_dir,\n",
    "        target_size = (IM_WIDTH, IM_HEIGHT),\n",
    "        batch_size = batch_size,\n",
    "    )\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        args.val_dir,\n",
    "        target_size = (IM_WIDTH, IM_HEIGHT),\n",
    "        batch_size = batch_size,\n",
    "    )\n",
    "\n",
    "    # setup model\n",
    "    base_model = InceptionV3(weights = 'imagenet', include_top = False)\n",
    "    #base_model = InceptionResNetV2(weights = 'imagenet', include_top = False)\n",
    "    #base_model = InceptionV4(weights = 'imagenet', include_top = False)\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "\n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model)\n",
    "\n",
    "    history_tl = model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs = epochs,\n",
    "        steps_per_epoch = nb_train_samples / batch_size,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = nb_val_samples / batch_size,\n",
    "        class_weight = 'auto',\n",
    "        callbacks = get_callbacks())\n",
    "\n",
    "    # fine-tuning\n",
    "    setup_to_finetune(model)\n",
    "\n",
    "    history_ft = model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs = epochs,\n",
    "        steps_per_epoch = nb_train_samples / batch_size,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = nb_val_samples / batch_size,\n",
    "        class_weight = 'auto',\n",
    "        callbacks = get_callbacks())\n",
    "\n",
    "    model.save(args.output_model_file)\n",
    "\n",
    "    if args.plot:\n",
    "        plot_training(history_ft)\n",
    "\n",
    "\n",
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.plot(epochs, val_loss, 'r-')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    train_dir = \"C:\\\\AID\\\\AID-split\\\\train\",\n",
    "    val_dir = \"C:\\\\AID\\\\AID-split\\\\test\",\n",
    "    output_model_file = \"inceptionv3-ft-2.h5\",\n",
    "    #output_model_file = \"inception_resnet_v2-ft.h5\",\n",
    "    #output_model_file = \"inceptionv4-ft.h5\",\n",
    "    epochs = EPOCHS,\n",
    "    batch_size = BAT_SIZE,\n",
    "    plot = True)\n",
    "\n",
    "if (not os.path.exists(args.train_dir)) or (not os.path.exists(args.val_dir)):\n",
    "    print(\"directories do not exist\")\n",
    "    sys.exit(1)\n",
    "\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception_v4 import InceptionV4, preprocess_input\n",
    "base_model = InceptionV4(weights = 'imagenet', include_top = False)\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
